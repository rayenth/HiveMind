# HiveMind - Automated Security for the Ecosystem

> *"The caravan moves on, and the dogs bark"*

Syst√®me de s√©curit√© automatis√© et intelligent capable de surveiller et de prot√©ger l'ensemble d'un √©cosyst√®me r√©seau.

---

## üìã Vue d'ensemble

HiveMind combine la surveillance en temps r√©el, la d√©tection d'anomalies bas√©e sur l'IA et des r√©ponses automatis√©es pour garantir une s√©curit√© continue de votre infrastructure.

**Couverture**: Ordinateurs, Serveurs, Routeurs, Commutateurs, Objets connect√©s (IoT)

---

## üèóÔ∏è Architecture

```
Devices ‚Üí DataStream (Kafka/Flink) ‚Üí Backend (Spring Boot) ‚Üí Database (Cassandra/PostgreSQL)
                ‚Üì                              ‚Üì
            ELK Stack                      AI (Ollama)
                ‚Üì                              ‚Üì
            Dashboard (React.js) ‚Üê WebSocket ‚Üê Alerts
```

---

## üöÄ Modules

### üìä [DataStream](./DataStream-work) - Traitement en temps r√©el
**Responsable**: Adem Ben Romdhane

Collecte et traitement des √©v√©nements en temps r√©el avec Apache Kafka et Apache Flink.

**API REST**: `POST http://localhost:8080/api/events`

**Topics Kafka**:
- `device-events-workstation`
- `device-events-server`
- `device-events-iot`
- `device-events-network`

[üìñ Documentation compl√®te](./DataStream-work/README.md)

---

### üîê Backend - Services & API
**Responsable**: Jasser Lefi

Services Spring Boot, API REST, int√©gration des bases de donn√©es et s√©curit√©.

---

### üîç Security & ELK - Analyse des logs
**Responsable**: Malek Boujazza

Mise en place de la suite ELK, analyse des logs et d√©tection des menaces.

#### üìä ELK Stack - R√¥le et Avantages

**ELK** (Elasticsearch, Logstash, Kibana) est le syst√®me central de collecte, traitement et visualisation des logs dans HiveMind.

##### üéØ R√¥le Principal

L'ELK Stack joue plusieurs r√¥les critiques dans l'√©cosyst√®me HiveMind:

1. **Collecte Centralis√©e des Logs**: Agr√®ge tous les logs provenant de diff√©rentes sources (IoT devices, services Spring Boot, alertes d'anomalies)
2. **Traitement et Enrichissement**: Transforme et normalise les donn√©es brutes en informations structur√©es
3. **Stockage Index√©**: Conserve les logs dans Elasticsearch pour des recherches rapides et efficaces
4. **Visualisation en Temps R√©el**: Fournit des dashboards Kibana pour surveiller l'√©tat du syst√®me

##### ‚ú® Avantages

- **üîç Recherche Rapide**: Elasticsearch permet des recherches full-text sur des millions de logs en millisecondes
- **üìà Scalabilit√©**: Architecture distribu√©e capable de g√©rer des volumes massifs de donn√©es
- **‚ö° Temps R√©el**: Traitement et visualisation des logs en temps r√©el pour une r√©activit√© maximale
- **üé® Visualisation Puissante**: Kibana offre des dashboards interactifs et personnalisables
- **üîó Int√©gration Kafka**: Consommation native des topics Kafka pour une int√©gration transparente
- **üìä Analyse Historique**: Stockage √† long terme permettant l'analyse de tendances et la d√©tection de patterns

##### üîÑ Processus de Traitement des Logs

```
IoT Devices (ESP32) ‚Üí iot-device-service ‚Üí Kafka (iot-logs topic)
                                              ‚Üì
                                    anomaly-detection-service
                                              ‚Üì
                                    Kafka (anomaly-alerts topic)
                                              ‚Üì
                                         Logstash
                                              ‚Üì
                                       Elasticsearch
                                              ‚Üì
                                          Kibana
```

**√âtapes d√©taill√©es**:

1. **G√©n√©ration des Logs**: Les devices IoT (ESP32) envoient des logs via HTTP POST au `iot-device-service`
2. **Publication Kafka**: Le service publie les logs sur le topic `iot-logs`
3. **D√©tection d'Anomalies**: Le `anomaly-detection-service` consomme les logs, d√©tecte les anomalies et publie des alertes sur `anomaly-alerts`
4. **Ingestion Logstash**: Logstash consomme le topic `anomaly-alerts` depuis Kafka
5. **Transformation**: Logstash applique des filtres (conversion timestamp, enrichissement)
6. **Indexation**: Les logs transform√©s sont index√©s dans Elasticsearch avec un index quotidien (`anomaly-alerts-YYYY.MM.dd`)
7. **Visualisation**: Kibana interroge Elasticsearch pour afficher les dashboards en temps r√©el

##### üîå Int√©gration avec les Composants

**Avec Kafka**:
```yaml
# logstash.conf
input {
  kafka {
    bootstrap_servers => "kafka:29092"
    topics => ["anomaly-alerts"]
    group_id => "logstash-anomaly-group"
    codec => "json"
  }
}
```

**Avec Elasticsearch**:
```yaml
output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "anomaly-alerts-%{+YYYY.MM.dd}"
  }
}
```

**Avec les Services Spring Boot**:
- `iot-device-service` (port 8080): G√©n√®re et publie les logs IoT
- `anomaly-detection-service` (port 8081): D√©tecte les anomalies et g√©n√®re des alertes

##### üìç Endpoints et Ports

| Service | Port | URL | Description |
|---------|------|-----|-------------|
| Elasticsearch | 9200 | http://localhost:9200 | API REST et stockage |
| Kibana | 5601 | http://localhost:5601 | Interface de visualisation |
| Logstash | 5044, 9600 | - | Ingestion et monitoring |

##### üöÄ Configuration Docker

L'ELK Stack est d√©ploy√© via Docker Compose avec les services suivants:

- **Elasticsearch**: Stockage distribu√© avec 256MB de heap
- **Kibana**: Interface web connect√©e √† Elasticsearch
- **Logstash**: Pipeline de traitement connect√© √† Kafka et Elasticsearch

**R√©seau**: Tous les services communiquent via le r√©seau `elk-network`

##### üìä Exemple de Flux de Donn√©es

```json
// 1. Log IoT envoy√© par ESP32
{
  "deviceId": "ESP32-001",
  "status": "ONLINE",
  "temperature": 85.5,
  "timestamp": "2025-12-18T19:46:40Z"
}

// 2. Alerte d'anomalie d√©tect√©e
{
  "alertId": "uuid-123",
  "deviceId": "ESP32-001",
  "description": "Temperature exceeds threshold",
  "detectedValue": 85.5,
  "timestamp": 1734551200
}

// 3. Log index√© dans Elasticsearch
{
  "@timestamp": "2025-12-18T19:46:40.000Z",
  "alertId": "uuid-123",
  "deviceId": "ESP32-001",
  "description": "Temperature exceeds threshold",
  "detectedValue": 85.5
}
```

---

### ü§ñ AI - D√©tection d'anomalies
**Responsable**: Eya Skhiri

Int√©gration d'Ollama pour l'analyse s√©mantique et la d√©tection d'anomalies.

---

### üé® DevOps & Frontend
**Responsable**: Ahmed Rayen Thabet

Automatisation, d√©ploiement, CI/CD et d√©veloppement du tableau de bord React.

---

## üõ†Ô∏è Technologies

- **Data Streaming**: Apache Kafka, Apache Flink, MQTT
- **Backend**: Spring Boot, Spring Security
- **Databases**: Cassandra, PostgreSQL
- **Monitoring**: ELK Stack (Elasticsearch, Logstash, Kibana)
- **AI**: Ollama
- **DevOps**: Docker, Kubernetes, Ansible
- **Frontend**: React.js

---

## üö¶ Quick Start

```bash
# 1. Cloner le projet
git clone https://github.com/iluvumua/HiveMind.git
cd HiveMind

# 2. D√©marrer le module DataStream
cd DataStream-work
docker-compose up -d

# 3. Cr√©er les topics Kafka
for topic in device-events-workstation device-events-iot device-events-network device-events-server; do
  docker exec kafka kafka-topics --create --bootstrap-server kafka:29092 --topic $topic --partitions 1 --replication-factor 1 --if-not-exists
done

# 4. Build et d√©marrer l'API
mvn clean package -DskipTests
mvn spring-boot:run

# 5. Tester l'API
curl -X POST http://localhost:8080/api/events \
  -H "Content-Type: application/json" \
  -d '{"eventType":"LOGIN_FAILURE","deviceId":"WS-001","severity":"CRITICAL","username":"alice","authenticationStatus":"FAILURE"}'
```

---

## üì° API Endpoints

### DataStream API

**Base URL**: `http://localhost:8080`

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/events` | Soumettre un √©v√©nement de s√©curit√© |
| GET | `/api/health` | V√©rifier l'√©tat de l'API |

**Exemple de payload**:
```json
{
  "eventType": "LOGIN_FAILURE",
  "deviceId": "WS-001",
  "severity": "CRITICAL",
  "username": "alice",
  "authenticationStatus": "FAILURE"
}
```

---

## üë• √âquipe

| R√¥le | Nom |
|------|-----|
| DevOps & Frontend | Ahmed Rayen Thabet |
| Data Stream Engineer | Adem Ben Romdhane |
| Security Engineer | Malek Boujazza |
| AI Engineer | Eya Skhiri |
| Backend Developer | Jasser Lefi |

---

## üìö Documentation

- [DataStream Module](./DataStream-work/README.md) - API Kafka/Flink
- [Backend API](#) - Services Spring Boot *(√† venir)*
- [ELK Stack Configuration](#-elk-stack---r√¥le-et-avantages) - Monitoring, logs et visualisation
- [AI Integration](#) - Ollama setup *(√† venir)*
- [Frontend Dashboard](#) - React.js *(√† venir)*

---

## üìù License

Projet acad√©mique - ENISO (√âcole Nationale d'Ing√©nieurs de Sousse)

---

**Status**: üü¢ En d√©veloppement actif
