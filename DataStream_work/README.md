# HiveMind DataStream - API Documentation

## üìã Overview

Module de traitement de flux de donn√©es en temps r√©el pour le projet **Automated Security for the Ecosystem**.

**Technologies**: Apache Kafka, Apache Flink, Spring Boot, Docker

---

## üîå Pour Jasser (Backend Developer)

### 1. API REST pour recevoir les √©v√©nements

**Endpoint**: `POST http://localhost:8080/api/events`

**Headers**: `Content-Type: application/json`

**Format JSON** (tous les champs sont requis):
```json
{
  "eventType": "LOGIN_FAILURE",
  "deviceId": "WS-001",
  "severity": "CRITICAL",
  "username": "alice",
  "authenticationStatus": "FAILURE",
  "deviceType": "WORKSTATION",
  "sourceIp": "192.168.1.100",
  "timestamp": "2025-12-04T10:00:00"
}
```

**Champs disponibles**:
- `eventType`: Type d'√©v√©nement (ex: `LOGIN_FAILURE`, `DISK_FULL`, `SUSPICIOUS_ACTIVITY`)
- `deviceId`: Identifiant unique de l'appareil
- `severity`: `LOW`, `MEDIUM`, `HIGH`, ou `CRITICAL`
- `username`: Nom d'utilisateur associ√© √† l'√©v√©nement
- `authenticationStatus`: `SUCCESS`, `FAILURE`, ou `NONE`
- `deviceType`: `WORKSTATION`, `SERVER`, `IOT`, ou `NETWORK`
- `sourceIp`: Adresse IP source
- `timestamp`: ISO 8601 format

**R√©ponse**: `Event received and forwarded to device-events-{type}`

### 2. Health Check

**Endpoint**: `GET http://localhost:8080/api/health`

**R√©ponse**: `HiveMind DataStream API is running`

---

## üìä Pour Malek (S√©curit√©/ELK)

### Topics Kafka disponibles

Pour consommer les √©v√©nements:
- `device-events-workstation` - √âv√©nements des postes de travail
- `device-events-server` - √âv√©nements des serveurs
- `device-events-iot` - √âv√©nements IoT
- `device-events-network` - √âv√©nements r√©seau (routeurs, switches)

**Kafka Bootstrap Server**: `localhost:9094`

**Consumer Group sugg√©r√©**: `elk-consumer-group`

### Exemple de consommation (Logstash)

```conf
input {
  kafka {
    bootstrap_servers => "localhost:9094"
    topics => ["device-events-workstation", "device-events-server", "device-events-iot", "device-events-network"]
    group_id => "elk-consumer-group"
    codec => "json"
  }
}
```

---

## ü§ñ Pour Eya (IA/Ollama)

### Option 1: Consommer depuis Kafka (Recommand√©)

Tu peux lire les √©v√©nements directement depuis les topics Kafka pour l'analyse IA.

### Option 2: Topic d√©di√© pour les alertes

Je peux cr√©er un topic sp√©cial `high-severity-alerts` qui ne contiendra que les √©v√©nements **HIGH** et **CRITICAL** pour optimiser ton traitement.

**Format des √©v√©nements** (d√©j√† en JSON, pr√™t pour Ollama):
```json
{
  "eventType": "SUSPICIOUS_ACTIVITY",
  "deviceId": "WS-001",
  "severity": "HIGH",
  "username": "alice",
  "authenticationStatus": "FAILURE"
}
```

---

## üöÄ Pour Rayen (DevOps/Frontend)

### Docker Compose

Tous les services sont conteneuris√©s:
- **Kafka**: Port 9094
- **Zookeeper**: Port 2181
- **Flink JobManager**: Port 8081 (Web UI)
- **Flink TaskManager**: Traitement interne
- **Spring Boot API**: Port 8080

### Commandes

```bash
# D√©marrer tous les services
docker-compose up -d

# Arr√™ter
docker-compose down

# Voir les logs
docker logs -f kafka
docker logs -f datastream-work-taskmanager-1
```

### Pour le Dashboard React

Tu peux:
1. **Appeler l'API REST** pour soumettre des √©v√©nements de test
2. **Consommer Kafka** via WebSocket pour afficher les alertes en temps r√©el
3. **Utiliser Flink Web UI** (http://localhost:8081) pour monitoring

---

## üì¶ Donn√©es disponibles en sortie (pour tous)

Flink traite les √©v√©nements et g√©n√®re:
- **Alertes HIGH/CRITICAL** avec tous les d√©tails (type, device, user, auth status)
- **√âv√©nements normaux** (LOW/MEDIUM) pour logging

### Prochaine √©tape

Je peux configurer Flink pour √©crire dans:
- **Cassandra** (pour Jasser - stockage historique)
- **PostgreSQL** (pour Jasser - base relationnelle)
- **Topic Kafka d√©di√©** (pour Eya - analyse IA)

---

## üîß Configuration requise

### Variables d'environnement

```bash
KAFKA_BOOTSTRAP_SERVERS=localhost:9094
```

### Ports utilis√©s

- `8080` - Spring Boot API
- `8081` - Flink Web UI
- `9094` - Kafka (externe)
- `2181` - Zookeeper

---

## üö¶ Quick Start

```bash
# 1. Cloner le repo
git clone https://github.com/iluvumua/HiveMind.git
cd HiveMind/DataStream-work

# 2. D√©marrer Docker
docker-compose up -d

# 3. Cr√©er les topics Kafka
for topic in device-events-workstation device-events-iot device-events-network device-events-server; do
  docker exec kafka kafka-topics --create --bootstrap-server kafka:29092 --topic $topic --partitions 1 --replication-factor 1 --if-not-exists
done

# 4. Build le projet
mvn clean package -DskipTests

# 5. D√©marrer Spring Boot API
mvn spring-boot:run

# 6. Soumettre le job Flink (via Web UI http://localhost:8081)
# Uploader: target/flink-job.jar
# Entry Class: com.hivemind.datastream.DataStreamJob

# 7. Tester
curl -X POST http://localhost:8080/api/events \
  -H "Content-Type: application/json" \
  -d '{"eventType":"LOGIN_FAILURE","deviceId":"WS-001","severity":"CRITICAL","username":"alice","authenticationStatus":"FAILURE"}'
```

---

## üìù TL;DR pour chaque membre

- **Jasser**: Utilise `POST http://localhost:8080/api/events` pour envoyer des √©v√©nements
- **Malek**: Consomme les topics Kafka (`device-events-*`) pour ELK
- **Eya**: Lis depuis Kafka ou je cr√©e un topic `alerts` pour toi
- **Rayen**: Tout est dockeris√©, `docker-compose up -d` pour d√©marrer

---

## üë• √âquipe

**Ing√©nieur Data Stream**: Adem Ben Romdhane

**Projet**: Automated Security for the Ecosystem
