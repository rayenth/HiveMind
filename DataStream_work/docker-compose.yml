services:
  kafka:
    image: confluentinc/cp-kafka:7.8.3
    container_name: kafka
    restart: always
    ports:
      - "9092:9092" # Changed: Expose 9092 for external access
      - "9093:9093" # Controller port
    environment:
      KAFKA_KRAFT_MODE: "true"
      CLUSTER_ID: "1L6g7nGhU-eAKfL--X25wo"
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      # Dual listeners: internal (kafka:29092) and external (localhost:9092)
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_kraft:/var/lib/kafka/data
    networks:
      - elk-network
    healthcheck:
      test: [ "CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1" ]
      interval: 10s
      timeout: 10s
      retries: 5
  jobmanager:
    image: flink:1.17.1-java11
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager

  taskmanager:
    image: flink:1.17.1-java11
    depends_on:
      - jobmanager
    command: taskmanager
    links:
      - "jobmanager:jobmanager"
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2
    networks:
      - elk-network

  #===elk===
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.2
    container_name: elasticsearch
    restart: always
    environment:
      - xpack.security.enabled=false
      - action.destructive_requires_name=false
      - ES_JAVA_OPTS=-Xmx256m -Xms256m
      - discovery.type=single-node
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elastic_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - elk-network
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5

  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.2
    container_name: kibana
    restart: always
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - "5601:5601"
    networks:
      - elk-network

  logstash:
    image: docker.elastic.co/logstash/logstash:8.15.2
    container_name: logstash
    restart: always
    volumes:
      - ../logstash/pipeline:/usr/share/logstash/pipeline	  
    environment:
      - LS_JAVA_OPTS=-Xms256m -Xmx256m
      - XPACK_MONITORING_ENABLED=false
    depends_on:
      elasticsearch:
        condition: service_healthy
      kafka:
        condition: service_healthy
    ports:
      - "5044:5044"
      - "9600:9600"
    networks:
      - elk-network

networks:
  elk-network:
    driver: bridge

volumes:
  elastic_data:
  kafka_kraft:
