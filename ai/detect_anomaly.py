"""
Module de d√©tection d'anomalies IA
Utilise Ollama pour analyser des logs r√©seau et d√©tecter des comportements suspects
"""

import json
import re
import os
import logging
from typing import Dict, List, Optional, Union
from ollama import chat
from datetime import datetime

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ============================================================================
# CONSTANTES DE CONFIGURATION
# ============================================================================

DEFAULT_MODEL = "llama3:latest"  # Mod√®le par d√©faut
LOGS_DIR = "logs"                # Dossier des logs √† analyser
ARCHIVE_DIR = "archive"          # Dossier d'archivage
SUPPORTED_ENCODINGS = ['utf-8', 'cp1252', 'latin-1', 'iso-8859-1']

# ============================================================================
# FONCTION PRINCIPALE DE D√âTECTION
# ============================================================================

def detect_anomaly(log_text: str, model: str = DEFAULT_MODEL) -> Dict:
    """
    Analyse un log r√©seau avec un mod√®le IA pour d√©tecter des anomalies
    
    Args:
        log_text (str): Le message de log √† analyser
        model (str): Nom du mod√®le Ollama √† utiliser (par d√©faut: "llama3:latest")
    
    Returns:
        Dict: R√©sultat d'analyse au format JSON contenant:
            - anomaly (bool): True si anomalie d√©tect√©e
            - confidence (float): Niveau de confiance (0.0 √† 1.0)
            - reason (str): Explication en fran√ßais
            - category (str): Type d'anomalie
            - model_used (str): Mod√®le utilis√© pour l'analyse
    
    Example:
        >>> result = detect_anomaly("Port scan detected from 192.168.1.100")
        >>> print(result)
        {
            "anomaly": true,
            "confidence": 0.92,
            "reason": "Scan de ports d√©tect√©, comportement suspect",
            "category": "network_scan",
            "model_used": "llama3:latest"
        }
    """
    
    # Construction du prompt pour le mod√®le IA
    prompt = f"""
    Tu es un expert en s√©curit√© r√©seau. Analyse ce log et d√©termine s'il s'agit d'une anomalie.
    
    CONTEXTE:
    - Un log normal: connexions r√©ussies, requ√™tes HTTP 200, activit√©s autoris√©es
    - Une anomalie: scans de ports, attaques DDoS, tentatives de bruteforce, acc√®s non autoris√©s
    
    LOG √Ä ANALYSER: "{log_text}"
    
    FORMAT DE R√âPONSE OBLIGATOIRE (JSON uniquement):
    {{
        "anomaly": true ou false,
        "confidence": un nombre entre 0.0 et 1.0,
        "reason": "explication courte en fran√ßais",
        "category": "type d'anomalie (si applicable)"
    }}
    
    R√©ponds uniquement avec le JSON, sans commentaires suppl√©mentaires.
    """
    
    try:
        logger.debug(f"Analyse du log avec le mod√®le '{model}': {log_text[:50]}...")
        
        # Appel au mod√®le IA via Ollama
        response = chat(
            model=model,
            messages=[{'role': 'user', 'content': prompt}],
            options={'temperature': 0.1}  # Faible temp√©rature pour des r√©ponses coh√©rentes
        )
        
        # Extraction de la r√©ponse
        response_text = response['message']['content']
        
        # Recherche du JSON dans la r√©ponse
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        
        if json_match:
            # Parsing du JSON
            result = json.loads(json_match.group(0))
            
            # Validation et normalisation du r√©sultat
            validated_result = {
                "anomaly": bool(result.get("anomaly", False)),
                "confidence": float(result.get("confidence", 0.5)),
                "reason": str(result.get("reason", "Analyse effectu√©e")),
                "category": str(result.get("category", "unknown")),
                "model_used": model
            }
            
            # S'assurer que la confiance est dans [0, 1]
            validated_result["confidence"] = max(0.0, min(1.0, validated_result["confidence"]))
            
            logger.info(f"Analyse termin√©e - Anomalie: {validated_result['anomaly']} (confiance: {validated_result['confidence']:.2f})")
            return validated_result
            
        else:
            # Aucun JSON trouv√© dans la r√©ponse
            logger.warning(f"Aucun JSON valide dans la r√©ponse du mod√®le: {response_text[:100]}...")
            return {
                "anomaly": False,
                "confidence": 0.0,
                "reason": "Format de r√©ponse invalide du mod√®le IA",
                "category": "parsing_error",
                "model_used": model
            }
            
    except json.JSONDecodeError as e:
        logger.error(f"Erreur de d√©codage JSON: {e}")
        return {
            "anomaly": False,
            "confidence": 0.0,
            "reason": f"Erreur de format JSON: {str(e)}",
            "category": "json_error",
            "model_used": model
        }
        
    except Exception as e:
        logger.error(f"Erreur lors de l'appel √† Ollama: {e}")
        return {
            "anomaly": False,
            "confidence": 0.0,
            "reason": f"Erreur de connexion au mod√®le IA: {str(e)}",
            "category": "connection_error",
            "model_used": model
        }

# ============================================================================
# FONCTIONS UTILITAIRES POUR LA GESTION DES FICHIERS
# ============================================================================

def ensure_directory(directory_path: str) -> None:
    """Cr√©e un dossier s'il n'existe pas"""
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)
        logger.info(f"Dossier cr√©√©: {directory_path}")

def detect_file_encoding(filepath: str) -> str:
    """
    D√©tecte l'encodage d'un fichier texte
    
    Args:
        filepath (str): Chemin du fichier
    
    Returns:
        str: Encodage d√©tect√© (ex: 'utf-8', 'cp1252')
    """
    try:
        import chardet
        with open(filepath, 'rb') as f:
            raw_data = f.read(10000)  # Lire les 10 premiers Ko
            detection = chardet.detect(raw_data)
            return detection.get('encoding', 'utf-8')
    except ImportError:
        logger.warning("Module chardet non install√©, utilisation de l'encodage par d√©faut")
        return 'utf-8'
    except Exception as e:
        logger.error(f"Erreur lors de la d√©tection d'encodage: {e}")
        return 'utf-8'

def read_log_file(filepath: str) -> List[str]:
    """
    Lit un fichier log en g√©rant automatiquement l'encodage
    
    Args:
        filepath (str): Chemin du fichier log
    
    Returns:
        List[str]: Liste des lignes du fichier
    """
    try:
        # Essayer diff√©rents encodages courants
        for encoding in SUPPORTED_ENCODINGS:
            try:
                with open(filepath, 'r', encoding=encoding) as f:
                    lines = [line.strip() for line in f if line.strip()]
                logger.debug(f"Fichier lu avec l'encodage: {encoding}")
                return lines
            except UnicodeDecodeError:
                continue
        
        # Si aucun encodage standard ne fonctionne
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            lines = [line.strip() for line in f if line.strip()]
        logger.warning(f"Fichier lu avec ignore errors: {filepath}")
        return lines
        
    except Exception as e:
        logger.error(f"Erreur lors de la lecture du fichier {filepath}: {e}")
        return []

# ============================================================================
# FONCTION D'ANALYSE DE FICHIERS COMPLETS
# ============================================================================

def analyze_log_file(filepath: str, model: str = DEFAULT_MODEL) -> Dict:
    """
    Analyse toutes les lignes d'un fichier log
    
    Args:
        filepath (str): Chemin du fichier √† analyser
        model (str): Mod√®le Ollama √† utiliser
    
    Returns:
        Dict: R√©sultats de l'analyse avec statistiques
    """
    logger.info(f"D√©but de l'analyse du fichier: {filepath}")
    
    # Lire le fichier
    lines = read_log_file(filepath)
    if not lines:
        return {
            "success": False,
            "error": "Fichier vide ou impossible √† lire",
            "file": os.path.basename(filepath)
        }
    
    # Analyser chaque ligne
    results = []
    anomalies = []
    
    for i, line in enumerate(lines, 1):
        result = detect_anomaly(line, model)
        result["line_number"] = i
        result["original_log"] = line
        results.append(result)
        
        if result["anomaly"]:
            anomalies.append(result)
        
        # Log progressif
        if i % 10 == 0:
            logger.debug(f"Progression: {i}/{len(lines)} lignes analys√©es")
    
    # Compilation des statistiques
    stats = {
        "total_lines": len(lines),
        "analyzed_lines": len(results),
        "anomalies_detected": len(anomalies),
        "anomaly_rate": len(anomalies) / len(results) if results else 0,
        "most_common_category": max(
            [r["category"] for r in results if r["anomaly"]],
            key=[r["category"] for r in results if r["anomaly"]].count,
            default="none"
        )
    }
    
    logger.info(f"Analyse termin√©e: {stats['anomalies_detected']} anomalies d√©tect√©es sur {stats['total_lines']} lignes")
    
    return {
        "success": True,
        "file": os.path.basename(filepath),
        "statistics": stats,
        "anomalies": anomalies,
        "sample_results": results[:5],  # Retourne les 5 premiers r√©sultats comme √©chantillon
        "model_used": model,
        "timestamp": datetime.now().isoformat()
    }

# ============================================================================
# FONCTION PRINCIPALE POUR L'ANALYSE EN LIGNE DE COMMANDE
# ============================================================================

def main():
    """Fonction principale pour l'ex√©cution en ligne de commande"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Analyseur de logs r√©seau avec IA')
    parser.add_argument('--log', type=str, help='Log unique √† analyser')
    parser.add_argument('--file', type=str, help='Fichier log √† analyser')
    parser.add_argument('--model', type=str, default=DEFAULT_MODEL, 
                       help=f"Mod√®le Ollama √† utiliser (d√©faut: {DEFAULT_MODEL})")
    parser.add_argument('--list-models', action='store_true', 
                       help='Lister les mod√®les Ollama disponibles')
    
    args = parser.parse_args()
    
    # Lister les mod√®les disponibles
    if args.list_models:
        try:
            from ollama import list as list_models
            models = list_models()
            print("üì¶ Mod√®les Ollama disponibles:")
            for model in models.get('models', []):
                print(f"  ‚Ä¢ {model['name']}")
        except Exception as e:
            print(f"‚ùå Erreur lors de la liste des mod√®les: {e}")
        return
    
    # Analyser un log unique
    if args.log:
        print(f"üîç Analyse du log avec le mod√®le '{args.model}':")
        print(f"   Log: {args.log}")
        result = detect_anomaly(args.log, args.model)
        print(f"üìä R√©sultat: {json.dumps(result, indent=2, ensure_ascii=False)}")
    
    # Analyser un fichier
    elif args.file:
        if os.path.exists(args.file):
            result = analyze_log_file(args.file, args.model)
            print(json.dumps(result, indent=2, ensure_ascii=False))
        else:
            print(f"‚ùå Fichier non trouv√©: {args.file}")
    
    # Mode interactif
    else:
        print("ü§ñ Analyseur de logs IA - Mode interactif")
        print("Tapez 'quit' pour quitter")
        print(f"Mod√®le par d√©faut: {DEFAULT_MODEL}")
        print("-" * 50)
        
        while True:
            try:
                log_input = input("\nüìù Entrez un log √† analyser: ").strip()
                if log_input.lower() in ['quit', 'exit', 'q']:
                    break
                if log_input:
                    result = detect_anomaly(log_input)
                    print(f"üìä R√©sultat: {json.dumps(result, indent=2, ensure_ascii=False)}")
            except KeyboardInterrupt:
                print("\n\nüëã Au revoir!")
                break
            except Exception as e:
                print(f"‚ùå Erreur: {e}")

if __name__ == "__main__":
    main()